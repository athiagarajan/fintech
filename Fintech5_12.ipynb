{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFWubkMYqVijd5fmyNxmMT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athiagarajan/fintech/blob/main/Fintech5_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7w7CcmwSMTzt",
        "outputId": "b485a78b-437e-432a-83d9-d58418098ac8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ede25e2e1fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cross_validation' from 'sklearn' (/usr/local/lib/python3.8/dist-packages/sklearn/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#!pip install yfinance\n",
        "#!pip uninstall ipympl#\n",
        "#!pip install ipympl\n",
        "#!pip install sklearn\n",
        "%matplotlib widget\n",
        "#%matplotlib ipympl\n",
        "from IPython.display import Javascript\n",
        "import bs4 as bs\n",
        "import datetime as dt\n",
        "import os\n",
        "import pandas_datareader.data as pdr\n",
        "import pickle\n",
        "import requests\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn import svm, cross_validation, neighbors\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# This enables custom widgets in the current cell's output.\n",
        "# Currently this must be included in each cell using custom widgets but this\n",
        "# should be a temporary restriction.\n",
        "display(Javascript('''\n",
        "  google.colab.widgets.installCustomManager('http://127.0.0.1:9897/manager.dev.js');\n",
        "'''))\n",
        "\n",
        "style.use('ggplot')\n",
        "\n",
        "\n",
        "def save_sp500_tickers():\n",
        "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
        "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
        "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "    tickers = []\n",
        "    for row in table.findAll('tr')[1:]:\n",
        "        ticker = row.findAll('td')[0].text\n",
        "        tickers.append(ticker)\n",
        "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
        "        pickle.dump(tickers, f)\n",
        "    return tickers\n",
        "\n",
        "\n",
        "# save_sp500_tickers()\n",
        "def get_data_from_yahoo(reload_sp500=False):\n",
        "    if reload_sp500:\n",
        "        tickers = save_sp500_tickers()\n",
        "    else:\n",
        "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
        "            tickers = pickle.load(f)\n",
        "    if not os.path.exists('stock_dfs'):\n",
        "        os.makedirs('stock_dfs')\n",
        "\n",
        "    start = dt.datetime(2010, 1, 1)\n",
        "    end = dt.datetime.now()\n",
        "    for ticker in tickers:\n",
        "        # just in case your connection breaks, we'd like to save our progress!\n",
        "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
        "            #print(ticker)\n",
        "            df = pdr.get_data_yahoo(ticker,start, end)\n",
        "            df.reset_index(inplace=True)\n",
        "            df.set_index(\"Date\", inplace=True)\n",
        "            #df = df.drop(\"Symbol\", axis=1)\n",
        "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
        "        else:\n",
        "            print('Already have {}'.format(ticker))\n",
        "\n",
        "\n",
        "#get_data_from_yahoo()\n",
        "\n",
        "def compile_data():\n",
        "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
        "        tickers = pickle.load(f)\n",
        "\n",
        "    main_df = pd.DataFrame()\n",
        "\n",
        "    for count, ticker in enumerate(tickers):\n",
        "        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
        "        df.set_index('Date', inplace=True)\n",
        "\n",
        "        df.rename(columns={'Adj Close': ticker}, inplace=True)\n",
        "        df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], 1, inplace=True)\n",
        "\n",
        "        if main_df.empty:\n",
        "            main_df = df\n",
        "        else:\n",
        "            main_df = main_df.join(df, how='outer')\n",
        "\n",
        "        if count % 10 == 0:\n",
        "            print(count)\n",
        "    print(main_df.head())\n",
        "    main_df.to_csv('sp500_joined_closes.csv')\n",
        "\n",
        "\n",
        "#compile_data()\n",
        "\n",
        "def visualize_data():\n",
        "    df = pd.read_csv('sp500_joined_closes.csv')\n",
        "    df_corr = df.corr()\n",
        "    print(df_corr.head())\n",
        "    df_corr.to_csv('sp500corr.csv')\n",
        "    data1 = df_corr.values\n",
        "    fig1 = plt.figure()\n",
        "    ax1 = fig1.add_subplot(111)\n",
        "\n",
        "    heatmap1 = ax1.pcolor(data1, cmap=plt.cm.RdYlGn)\n",
        "    fig1.colorbar(heatmap1)\n",
        "\n",
        "    ax1.set_xticks(np.arange(data1.shape[1]) + 0.5, minor=False)\n",
        "    ax1.set_yticks(np.arange(data1.shape[0]) + 0.5, minor=False)\n",
        "    ax1.invert_yaxis()\n",
        "    ax1.xaxis.tick_top()\n",
        "    column_labels = df_corr.columns\n",
        "    row_labels = df_corr.index\n",
        "    ax1.set_xticklabels(column_labels)\n",
        "    ax1.set_yticklabels(row_labels)\n",
        "    plt.xticks(rotation=90)\n",
        "    heatmap1.set_clim(-1, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#visualize_data()\n",
        "def process_data_for_labels(ticker):\n",
        "    hm_days = 7\n",
        "    df = pd.read_csv('sp500_joined_closes.csv', index_col=0)\n",
        "    tickers = df.columns.values.tolist()\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    for i in range(1,hm_days+1):\n",
        "        df['{}_{}d'.format(ticker,i)] = (df[ticker].shift(-i) - df[ticker]) / df[ticker]\n",
        "\n",
        "    df.fillna(0, inplace=True)\n",
        "    return tickers, df\n",
        "\n",
        "def buy_sell_hold(*args):\n",
        "    cols = [c for c in args]\n",
        "    requirement = 0.02\n",
        "    for col in cols:\n",
        "        if col > requirement:\n",
        "            return 1\n",
        "        if col < -requirement:\n",
        "            return -1\n",
        "    return 0\n",
        "\n",
        "def extract_featuresets(ticker):\n",
        "    tickers, df = process_data_for_labels(ticker)\n",
        "\n",
        "    df['{}_target'.format(ticker)] = list(map( buy_sell_hold,\n",
        "                                               df['{}_1d'.format(ticker)],\n",
        "                                               df['{}_2d'.format(ticker)],\n",
        "                                               df['{}_3d'.format(ticker)],\n",
        "                                               df['{}_4d'.format(ticker)],\n",
        "                                               df['{}_5d'.format(ticker)],\n",
        "                                               df['{}_6d'.format(ticker)],\n",
        "                                               df['{}_7d'.format(ticker)]))\n",
        "\n",
        "    vals = df['{}_target'.format(ticker)].values.tolist()\n",
        "    str_vals = [str(i) for i in vals]\n",
        "    print('Data spread:', Counter(str_vals))\n",
        "\n",
        "    df.fillna(0, inplace=True)\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df_vals = df[[ticker for ticker in tickers]].pct_change()\n",
        "    df_vals = df_vals.replace([np.inf, -np.inf], 0)\n",
        "    df_vals.fillna(0, inplace=True)\n",
        "\n",
        "    X = df_vals.values\n",
        "    y = df['{}_target'.format(ticker)].values\n",
        "    return X, y, df\n",
        "\n",
        "def do_ml(ticker):\n",
        "    X, y, df = extract_featuresets(ticker)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.25)\n",
        "\n",
        "    clf = VotingClassifier([('lsvc', svm.LinearSVC()),\n",
        "                            ('knn', neighbors.KNeighborsClassifier()),\n",
        "                            ('rfor', RandomForestClassifier())])\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    confidence = clf.score(X_test, y_test)\n",
        "    print('accuracy:', confidence)\n",
        "    predictions = clf.predict(X_test)\n",
        "    print('predicted class counts:', Counter(predictions))\n",
        "    print()\n",
        "    print()\n",
        "    return confidence\n",
        "\n",
        "\n",
        "# examples of running:\n",
        "'''\n",
        "do_ml('XOM')\n",
        "do_ml('AAPL')\n",
        "do_ml('ABT')\n",
        "'''"
      ]
    }
  ]
}